import argparse # ì˜µì…˜ ì¡°ì ˆìš© ë„êµ¬
import database
from scrapers.naver_scraper import NaverScraper
from scrapers.hankyung_scraper import HankyungScraper
from analysis.history_manager import HistoryManager
from database.fetch_stock_prices import update_prices # ë°©ê¸ˆ ë§Œë“  ì£¼ê°€ ìˆ˜ì§‘ê¸°
import sqlite3
import pandas as pd

def main():
    # 1. ì‹¤í–‰ ì˜µì…˜ ì„¤ì •
    parser = argparse.ArgumentParser()
    parser.add_argument('--update-prices', action='store_true', help='ì£¼ê°€ ë°ì´í„°ë¥¼ ìƒˆë¡œ ìˆ˜ì§‘í• ì§€ ì—¬ë¶€')
    args = parser.parse_args()

    print("ğŸš€ [ExpertAlpha-K100 v3.0] ì‹œìŠ¤í…œ ê°€ë™...")

    # 2. DB ì´ˆê¸°í™”
    database.init_db()

    # 3. ì£¼ê°€ ìˆ˜ì§‘ (ì˜µì…˜ì´ ì¼œì ¸ ìˆì„ ë•Œë§Œ!)
    if args.update_prices:
        print("ğŸ“Š ì£¼ê°€ ë°ì´í„° ì—…ë°ì´íŠ¸ ëª¨ë“œ í™œì„±í™”...")
        update_prices()
    else:
        print("â© ì£¼ê°€ ì—…ë°ì´íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤. (ê¸°ì¡´ ë°ì´í„° ì‚¬ìš©)")

    # 4. ë¦¬í¬íŠ¸ ìˆ˜ì§‘ (ë„¤ì´ë²„/í•œê²½)
    naver = NaverScraper(db_path='expert_alpha_v3.db')
    naver.fetch_data(pages=5)

    hankyung = HankyungScraper(db_path='expert_alpha_v3.db')
    hankyung.fetch_data(pages=3)

    # 5. ì„±ì  ê¸°ë¡ ë° ë¶„ì„
    history = HistoryManager(db_path='expert_alpha_v3.db')
    history.record_daily_scores()

    # 6. ê²°ê³¼ í™•ì¸
    print("\nğŸ† ì˜¤ëŠ˜ì˜ ì „ë¬¸ê°€ ì‹¤ë ¥ ìˆœìœ„ (Top 5)")
    conn = sqlite3.connect('expert_alpha_v3.db')
    report_query = """
    SELECT s.name, s.organization, s.provider, h.avg_alpha, h.total_count
    FROM performance_history h
    JOIN sources s ON h.source_id = s.source_id
    WHERE h.record_date = date('now')
    ORDER BY h.avg_alpha DESC
    LIMIT 5
    """
    try:
        df = pd.read_sql_query(report_query, conn)
        if df.empty:
            print("ğŸ¤” ê³„ì‚°ëœ ì„±ì ì´ ì•„ì§ ì—†ìŠµë‹ˆë‹¤. ì£¼ê°€ ë°ì´í„°ê°€ ë¶€ì¡±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            print(df)
    except:
        print("ê²°ê³¼ ì¶œë ¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
    finally:
        conn.close()

if __name__ == "__main__":
    main()
