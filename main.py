import database
from scrapers.naver_scraper import NaverScraper
from scrapers.hankyung_scraper import HankyungScraper
from analysis.history_manager import HistoryManager
import sqlite3
import pandas as pd

def main():
    print("ğŸš€ [ExpertAlpha-K100 v3.0] ì‹œìŠ¤í…œ ê°€ë™...")

    # 1. DB ì´ˆê¸°í™” (í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìƒì„±)
    database.init_db()

    # 2. ë„¤ì´ë²„ ì •ë°€ ìˆ˜ì§‘ (10í˜ì´ì§€ í…ŒìŠ¤íŠ¸)
    naver = NaverScraper(db_path='expert_alpha_v3.db')
    naver.fetch_data(pages=10)

    # 3. í•œê²½ ì •ë°€ ìˆ˜ì§‘ (5í˜ì´ì§€ í…ŒìŠ¤íŠ¸)
    hankyung = HankyungScraper(db_path='expert_alpha_v3.db')
    hankyung.fetch_data(pages=5)

    # 4. ì¼ì¼ ì„±ì  íˆìŠ¤í† ë¦¬ ê¸°ë¡
    history = HistoryManager(db_path='expert_alpha_v3.db')
    history.record_daily_scores()

    # 5. ê²°ê³¼ í™•ì¸ (ì˜¤ëŠ˜ ê¸°ë¡ëœ ìƒìœ„ 5ëª… ë¦¬í¬íŠ¸)
    print("\nğŸ† ì˜¤ëŠ˜ì˜ ì „ë¬¸ê°€ ì‹¤ë ¥ ìˆœìœ„ (Top 5)")
    conn = sqlite3.connect('expert_alpha_v3.db')
    report_query = """
    SELECT s.name, s.organization, s.provider, h.avg_alpha, h.total_count
    FROM performance_history h
    JOIN sources s ON h.source_id = s.source_id
    WHERE h.record_date = date('now')
    ORDER BY h.avg_alpha DESC
    LIMIT 5
    """
    try:
        df = pd.read_sql_query(report_query, conn)
        if df.empty:
            print("ë°ì´í„°ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤. (ì£¼ê°€ ë°ì´í„°ì™€ì˜ ë§¤ì¹­ ì‹œê°„ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        else:
            print(df)
    except:
        print("ê²°ê³¼ ì¶œë ¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ë°ì´í„° ì ì¬ ì¤‘)")
    finally:
        conn.close()

    print("\nğŸ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. íˆìŠ¤í† ë¦¬ê°€ ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
