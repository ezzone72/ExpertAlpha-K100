import requests
from bs4 import BeautifulSoup
import sqlite3
import time

class NaverScraper:
    def __init__(self, db_path='expert_alpha_v3.db'):
        self.db_path = db_path
        self.provider = "NAVER"

    def fetch_data(self, pages=10):
        # DB ì—°ê²° (ìƒìœ„ í´ë”ì— ìˆëŠ” dbíŒŒì¼ì„ ì°¾ì•„ê°€ì•¼ í•˜ë¯€ë¡œ ê²½ë¡œ ì£¼ì˜)
        conn = sqlite3.connect(self.db_path)
        cur = conn.cursor()
        headers = {'User-Agent': 'Mozilla/5.0'}
        
        print(f"ğŸ“¡ {self.provider} ì •ë°€ ìˆ˜ì§‘ ì‹œì‘ (ì‹¤ëª… ì¶”ì¶œ ëª¨ë“œ)...")

        for page in range(1, pages + 1):
            url = f"https://finance.naver.com/research/company_list.naver?&page={page}"
            resp = requests.get(url, headers=headers)
            soup = BeautifulSoup(resp.text, 'html.parser')
            
            # ë¦¬ìŠ¤íŠ¸ í…Œì´ë¸” í–‰ ì¶”ì¶œ
            rows = soup.select('table.type_1 tr')
            for row in rows:
                cols = row.select('td')
                if len(cols) < 5: continue
                
                # ë°ì´í„° íŒŒì‹±
                stock_name = cols[0].text.strip()
                title = cols[1].text.strip()
                
                # [ì¤‘ìš”] ì‘ì„±ì ì •ë³´ ì •ë°€ ë¶„ë¦¬ (ì¦ê¶Œì‚¬ | ì´ë¦„)
                author_raw = cols[2].text.strip()
                if '|' in author_raw:
                    org, name = [x.strip() for x in author_raw.split('|')]
                else:
                    org = author_raw
                    name = "Unknown" # ì‹¤ëª…ì´ ì—†ì„ ê²½ìš°

                date = "20" + cols[4].text.strip().replace('.', '-') # 26.02.02 -> 2026-02-02

                # 1. ì¶œì²˜(sources) í…Œì´ë¸” ì €ì¥
                cur.execute("""
                    INSERT OR IGNORE INTO sources (name, type, provider, organization)
                    VALUES (?, ?, ?, ?)
                """, (name, 'ANALYST', self.provider, org))
                
                # ì €ì¥ëœ source_id ê°€ì ¸ì˜¤ê¸°
                cur.execute("SELECT source_id FROM sources WHERE name = ? AND provider = ?", (name, self.provider))
                res = cur.fetchone()
                if res:
                    source_id = res[0]
                    
                    # 2. ë°œì–¸(statements) í…Œì´ë¸” ì €ì¥
                    cur.execute("""
                        INSERT INTO statements (source_id, stock_name, issue_date, title)
                        VALUES (?, ?, ?, ?)
                    """, (source_id, stock_name, date, title))

            print(f"   - {self.provider} {page}í˜ì´ì§€ ì™„ë£Œ")
            time.sleep(0.3)

        conn.commit()
        conn.close()
        print(f"ğŸ {self.provider} ìˆ˜ì§‘ ì¢…ë£Œ.")

if __name__ == "__main__":
    # ë‹¨ë… ì‹¤í–‰ í…ŒìŠ¤íŠ¸ìš© (ê²½ë¡œëŠ” í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€)
    scraper = NaverScraper('../expert_alpha_v3.db')
    scraper.fetch_data(5)
