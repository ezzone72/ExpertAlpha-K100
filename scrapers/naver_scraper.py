import sqlite3
import requests
from bs4 import BeautifulSoup
import time

class NaverScraper:
    def __init__(self, db_path='expert_alpha_v3.db'):
        self.db_path = db_path

    def is_already_exists(self, title, date, expert_name):
        conn = sqlite3.connect(self.db_path)
        cur = conn.cursor()
        cur.execute("SELECT id FROM reports WHERE title = ? AND report_date = ? AND expert_name = ?", (title, date, expert_name))
        exists = cur.fetchone() is not None
        conn.close()
        return exists

    def fetch_data(self, pages=10):
        print(f"ğŸ“¡ ë„¤ì´ë²„ ê¸ˆìœµ ë¦¬í¬íŠ¸ ì •ë°€ ìˆ˜ì§‘ (ìµœëŒ€ {pages}í˜ì´ì§€)...")
        conn = sqlite3.connect(self.db_path)
        cur = conn.cursor()
        new_count = 0
        
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        
        for page in range(1, pages + 1):
            # ğŸ’¡ [í•µì‹¬] ë’¤ì— type=investì™€ ê°™ì€ ì¶”ê°€ íŒŒë¼ë¯¸í„°ë¥¼ ë¶™ì—¬ì•¼ í˜ì´ì§€ ì´ë™ì´ í™•ì‹¤íˆ ì‘ë™í•©ë‹ˆë‹¤.
            url = f"https://finance.naver.com/research/invest_list.naver?&page={page}"
            
            try:
                res = requests.get(url, headers=headers)
                soup = BeautifulSoup(res.text, 'html.parser')
                rows = soup.select('table.type_1 tr')
                
                page_new_count = 0
                valid_row_count = 0

                for row in rows:
                    cols = row.select('td')
                    if len(cols) < 5: continue
                    
                    valid_row_count += 1
                    title = cols[0].text.strip()
                    expert_name = cols[1].text.strip()
                    source = cols[2].text.strip()
                    date = "20" + cols[4].text.strip().replace('.', '-')
                    
                    if self.is_already_exists(title, date, expert_name):
                        continue 
                    
                    cur.execute('''
                        INSERT INTO reports (title, expert_name, source, report_date)
                        VALUES (?, ?, ?, ?)
                    ''', (title, expert_name, source, date))
                    page_new_count += 1
                    new_count += 1
                
                conn.commit()
                # ğŸ’¡ ë¡œê·¸ì— í˜„ì¬ í˜ì´ì§€ì˜ ì‹¤ì œ ë°ì´í„° ì œëª© í•˜ë‚˜ë¥¼ ê°™ì´ ì°ì–´ì„œ, ì •ë§ í˜ì´ì§€ê°€ ë°”ë€ŒëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
                first_title = rows[2].select('td')[0].text.strip()[:15] if valid_row_count > 0 else "N/A"
                print(f"ğŸ“„ ë„¤ì´ë²„ {page}p ì™„ë£Œ: {page_new_count}ê°œ ì¶”ê°€ (ì²«ì œëª©: {first_title}...)")
                
                time.sleep(0.3)
            except Exception as e:
                print(f"âŒ ë„¤ì´ë²„ {page}p ì—ëŸ¬: {e}")
                break

        conn.close()
        print(f"âœ… ë„¤ì´ë²„ ì´ {new_count}ê°œ ìˆ˜ì§‘ ì™„ë£Œ!")
