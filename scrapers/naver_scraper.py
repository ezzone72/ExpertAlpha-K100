import sqlite3, requests, re, time
from bs4 import BeautifulSoup

class NaverScraper:
    def __init__(self, db_path='expert_alpha_v3.db'):
        self.db_path = db_path

    def fetch_data(self, pages=50):
        print(f"ğŸ“¡ ë„¤ì´ë²„ {pages}í˜ì´ì§€ ì •ë°€ ìˆ˜ì§‘ ê°€ë™...")
        conn = sqlite3.connect(self.db_path)
        cur = conn.cursor()
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        
        for page in range(1, pages + 1):
            url = f"https://finance.naver.com/research/invest_list.naver?&page={page}"
            try:
                res = requests.get(url, headers=headers)
                soup = BeautifulSoup(res.text, 'html.parser')
                rows = soup.select('table.type_1 tr')
                
                for row in rows:
                    cols = row.select('td')
                    if len(cols) < 5: continue
                    
                    title_a = cols[0].select_one('a')
                    full_title = title_a.text.strip() if title_a else cols[0].text.strip()
                    
                    # ğŸ’¡ 1ìˆœìœ„: ì œëª©ì—ì„œ ì¢…ëª©ëª…ê³¼ ì½”ë“œ ì¶”ì¶œ (ì˜ˆ: ì‚¼ì„±ì „ì(005930))
                    stock_name, stock_code = "", ""
                    name_code_match = re.search(r'(.+?)\((\d{6})\)', full_title)
                    if name_code_match:
                        stock_name = name_code_match.group(1).strip()
                        stock_code = name_code_match.group(2).strip()
                    
                    # ğŸ’¡ 2ìˆœìœ„: ì œëª©ì—” ì—†ì§€ë§Œ ë§í¬ ì£¼ì†Œì— ì½”ë“œê°€ ìˆ¨ì–´ìˆëŠ” ê²½ìš° (ë„¤ì´ë²„ íŠ¹ì„±)
                    if not stock_code and title_a and 'href' in title_a.attrs:
                        code_match = re.search(r'itemCode=(\d{6})', title_a['href'])
                        if code_match:
                            stock_code = code_match.group(1)

                    expert = cols[1].text.strip()
                    source = cols[2].text.strip()
                    
                    # ë‚ ì§œ (24.12.15 -> 2024-12-15)
                    raw_date = cols[4].text.strip()
                    report_date = f"20{raw_date.replace('.', '-')}" if len(raw_date) == 8 else raw_date.replace('.', '-')

                    # ëª©í‘œê°€ ì¶”ì¶œ
                    target_price = 0
                    price_match = re.search(r'(\d{1,3}(,\d{3})+)', full_title)
                    if price_match:
                        target_price = int(price_match.group(1).replace(',', ''))

                    # ğŸ’¡ DB ì €ì¥ (ì •í•´ì§„ ì¹¸ì— ì™ì™)
                    cur.execute('''
                        INSERT INTO reports (report_date, stock_code, stock_name, title, target_price, expert_name, source) 
                        VALUES (?, ?, ?, ?, ?, ?, ?)
                    ''', (report_date, stock_code, stock_name, full_title, target_price, expert, source))
                
                conn.commit()
                # ì˜ ë˜ê³  ìˆëŠ”ì§€ ë¡œê·¸ë¡œ í™•ì¸!
                if stock_code:
                    print(f"ğŸ“„ {page}p ì™„ë£Œ: ìµœê·¼ ìˆ˜ì§‘ ì¢…ëª© [{stock_name}({stock_code})]")
                else:
                    print(f"ğŸ“„ {page}p ì™„ë£Œ: (ì‹œì¥/ì„¹í„° ë¦¬í¬íŠ¸ ìœ„ì£¼)")
                
                time.sleep(0.3)
            except Exception as e:
                print(f"âŒ {page}p ì—ëŸ¬: {e}")
                break
        conn.close()
