import sqlite3
import requests
from bs4 import BeautifulSoup
import time
import re

class NaverScraper:
    def __init__(self, db_path='expert_alpha_v3.db'):
        self.db_path = db_path

    def fetch_data(self, pages=10):
        print(f"ğŸ“¡ ë„¤ì´ë²„ ê¸ˆìœµ ë¦¬í¬íŠ¸ [ì •ë°€ ë¶„ì„í˜•] ìˆ˜ì§‘ ì‹œì‘...")
        conn = sqlite3.connect(self.db_path)
        cur = conn.cursor()
        new_count = 0
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        
        for page in range(1, pages + 1):
            url = f"https://finance.naver.com/research/invest_list.naver?&page={page}"
            try:
                res = requests.get(url, headers=headers)
                soup = BeautifulSoup(res.text, 'html.parser')
                # ë°ì´í„°ê°€ ìˆëŠ” í…Œì´ë¸” í–‰(tr)
                rows = soup.select('table.type_1 tr')
                
                for row in rows:
                    cols = row.select('td')
                    if len(cols) < 5: continue
                    
                    # 1. ì¢…ëª©ëª… ë° ì¢…ëª©ì½”ë“œ ì¶”ì¶œ (ì œëª© ì˜†ì˜ ë§í¬ì—ì„œ ì¶”ì¶œ)
                    title_cell = cols[0]
                    title = title_cell.text.strip()
                    
                    # ìƒì„¸ í˜ì´ì§€ ë§í¬ë‚˜ ì¢…ëª© ì—°ê²° ë§í¬ê°€ ìˆëŠ”ì§€ í™•ì¸
                    link_tag = title_cell.select_one('a')
                    stock_code = ""
                    if link_tag and 'href' in link_tag.attrs:
                        # hrefì—ì„œ itemCode=000000 í˜•íƒœë¥¼ ì¶”ì¶œ
                        code_match = re.search(r'itemCode=(\d{6})', link_tag['href'])
                        if code_match:
                            stock_code = code_match.group(1)

                    # 2. ì „ë¬¸ê°€, ì¦ê¶Œì‚¬, ë‚ ì§œ
                    expert = cols[1].text.strip()
                    source = cols[2].text.strip()
                    raw_date = cols[4].text.strip()
                    date = "20" + raw_date.replace('.', '-') if len(raw_date) == 8 else raw_date.replace('.', '-')

                    # 3. ëª©í‘œì£¼ê°€ (í•œê²½ì€ í‘œì— ìˆì§€ë§Œ ë„¤ì´ë²„ëŠ” ì œëª©ì— ì„ì—¬ ìˆëŠ” ê²½ìš°ê°€ ë§ìŒ)
                    # ìš°ì„ ì€ ê¸°ë³¸ ì»¬ëŸ¼ ìœ„ì£¼ë¡œ ìˆ˜ì§‘í•˜ë˜, ì¢…ëª©ì½”ë“œë¥¼ í™•ë³´í•˜ëŠ” ê²ƒì´ ê¸‰ì„ ë¬´ì…ë‹ˆë‹¤.
                    
                    # ì¤‘ë³µ ì²´í¬
                    cur.execute("SELECT id FROM reports WHERE title=? AND report_date=? AND expert_name=?", (title, date, expert))
                    if cur.fetchone(): continue
                    
                    # 4. DB ì €ì¥ (ì¢…ëª©ì½”ë“œ í¬í•¨)
                    cur.execute('''
                        INSERT INTO reports (title, expert_name, source, report_date, stock_code) 
                        VALUES (?, ?, ?, ?, ?)
                    ''', (title, expert, source, date, stock_code))
                    new_count += 1
                
                conn.commit()
                print(f"ğŸ“„ ë„¤ì´ë²„ {page}p ì™„ë£Œ: {new_count}ê°œ ëˆ„ì  ì €ì¥ (ìµœê·¼ì½”ë“œ: {stock_code})")
                time.sleep(0.3)
            except Exception as e:
                print(f"âŒ ì—ëŸ¬: {e}")
                break
        
        conn.close()
