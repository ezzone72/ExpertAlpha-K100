import sqlite3, requests, re, time
from bs4 import BeautifulSoup

class HankyungScraper:
    def __init__(self, db_path='expert_alpha_v4.db'):
        self.db_path = db_path

    def fetch_data(self, pages=50):
        conn = sqlite3.connect(self.db_path)
        cur = conn.cursor()
        # ğŸ’¡ ë¸Œë¼ìš°ì €ì¸ ì²™ ì†ì´ëŠ” í—¤ë” ë³´ê°•
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Referer': 'http://consensus.hankyung.com/'
        }
        
        success_count = 0
        for page in range(1, pages + 1):
            url = f"http://consensus.hankyung.com/apps.analysis/analysis.list?&page={page}"
            try:
                res = requests.get(url, headers=headers, timeout=20)
                res.encoding = 'euc-kr' 
                
                # ğŸ’¡ BeautifulSoupì´ ëª» ì½ì„ ê²ƒì— ëŒ€ë¹„í•´ ì •ê·œì‹ìœ¼ë¡œ ì§ì ‘ íƒ€ê²©
                # <tr> ì•ˆì˜ <td>ë“¤ì„ ë©ì–´ë¦¬ì§¸ ë‚šì•„ì±•ë‹ˆë‹¤.
                html = res.text
                rows = re.findall(r'<tr.*?>(.*?)</tr>', html, re.DOTALL)
                
                for row_html in rows:
                    cols = re.findall(r'<td.*?>(.*?)</td>', row_html, re.DOTALL)
                    if len(cols) < 5: continue
                    
                    # íƒœê·¸ ì œê±°í•˜ê³  ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
                    clean_cols = [re.sub(r'<.*?>', '', c).strip() for c in cols]
                    
                    report_date = clean_cols[0]
                    # ë‚ ì§œ í˜•ì‹ ì²´í¬ (ì˜ˆ: 2026-02-02)
                    if not re.match(r'\d{4}-\d{2}-\d{2}', report_date): continue
                    
                    full_title = clean_cols[1]
                    target_price_raw = clean_cols[2].replace(',', '')
                    target_price = int(re.search(r'\d+', target_price_raw).group()) if re.search(r'\d+', target_price_raw) else 0
                    expert = clean_cols[3]
                    source = clean_cols[4]
                    
                    # ì¢…ëª©ì½”ë“œ ì¶”ì¶œ (000000)
                    code_match = re.search(r'\((\d{6})\)', full_title)
                    if code_match:
                        stock_code = code_match.group(1)
                        stock_name = full_title.split('(')[0].strip()[-10:]
                        
                        cur.execute('''
                            INSERT INTO reports (report_date, stock_code, stock_name, target_price, expert_name, source_name, title, report_source) 
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                        ''', (report_date, stock_code, stock_name, target_price, expert, source, full_title, "Hankyung"))
                        success_count += 1
                
                conn.commit()
                print(f"âœ” {page}í˜ì´ì§€ ì™„ë£Œ (í˜„ì¬ ëˆ„ì  {success_count}ê±´)")
                time.sleep(0.7) # ì„œë²„ ì°¨ë‹¨ ë°©ì§€ìš© ë”œë ˆì´ ì‚´ì§ ì¦ê°€
            except Exception as e:
                print(f"âŒ {page}p ì—ëŸ¬: {e}")
                continue
        conn.close()
