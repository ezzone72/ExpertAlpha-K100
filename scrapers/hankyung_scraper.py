import sqlite3, requests, re, time
from bs4 import BeautifulSoup

class HankyungScraper:
    def __init__(self, db_path='expert_alpha_v4.db'):
        self.db_path = db_path

    def fetch_data(self, pages=50):
        conn = sqlite3.connect(self.db_path)
        cur = conn.cursor()
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        
        success_count = 0
        for page in range(1, pages + 1):
            url = f"http://consensus.hankyung.com/apps.analysis/analysis.list?&page={page}"
            try:
                res = requests.get(url, headers=headers, timeout=15)
                # ğŸ’¡ í•œê¸€ ê¹¨ì§ ë°©ì§€
                res.encoding = 'euc-kr' 
                soup = BeautifulSoup(res.text, 'html.parser')
                
                # ğŸ’¡ ëª¨ë“  í…Œì´ë¸” í–‰(tr)ì„ ë‹¤ ë’¤ì§‘ë‹ˆë‹¤.
                rows = soup.find_all('tr')
                
                for row in rows:
                    cols = row.find_all('td')
                    if len(cols) < 5: continue # ë°ì´í„°ê°€ ìˆëŠ” í–‰ë§Œ ê³¨ë¼ëƒ„
                    
                    # ì‘ì„±ì¼ (ì˜ˆ: 2026-02-02)
                    report_date = cols[0].text.strip()
                    if not re.match(r'\d{4}-\d{2}-\d{2}', report_date): continue
                    
                    # ì œëª© ë° ì¢…ëª©ì •ë³´
                    title_td = cols[1]
                    title_a = title_td.find('a')
                    if not title_a: continue
                    full_title = title_a.text.strip()
                    
                    # ëª©í‘œê°€
                    tp_raw = cols[2].text.strip().replace(',', '')
                    target_price = int(re.sub(r'[^0-9]', '', tp_raw)) if any(d.isdigit() for d in tp_raw) else 0
                    
                    # ì „ë¬¸ê°€ ë° ì¦ê¶Œì‚¬
                    expert = cols[3].text.strip()
                    source = cols[4].text.strip()
                    
                    # ì¢…ëª©ì½”ë“œ (ì œëª©ì—ì„œ (000000) í˜•íƒœ ì¶”ì¶œ)
                    code_match = re.search(r'\((\d{6})\)', full_title)
                    if code_match:
                        stock_code = code_match.group(1)
                        stock_name = full_title.split('(')[0].strip()[-10:]
                        
                        cur.execute('''
                            INSERT INTO reports (report_date, stock_code, stock_name, target_price, expert_name, source_name, title, report_source) 
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                        ''', (report_date, stock_code, stock_name, target_price, expert, source, full_title, "Hankyung"))
                        success_count += 1
                
                conn.commit()
                print(f"âœ” {page}í˜ì´ì§€ ì™„ë£Œ (í˜„ì¬ ëˆ„ì  {success_count}ê±´)")
                time.sleep(0.5)
            except Exception as e:
                print(f"âŒ {page}p ì—ëŸ¬: {e}")
                continue
        conn.close()
